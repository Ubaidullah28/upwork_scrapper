Search Query,Title,Job Link,Tags,Client Spent,Payment Info,Budget Type,Lower Hourly Rate,Higher Hourly Rate,Fixed Price,Payment Verified/Unverified,Description,Posted Time
Data Engineer,Senior Backend Engineer,https://www.upwork.com/jobs/Senior-Backend-span-class-highlight-Engineer-span_~021953480770957369833/?referrer_url_path=/nx/search/jobs/,"PostgreSQL, Docker, Kubernetes, Apache Kafka, Java, RESTful API, Python, API","$1K+
spent","Est. budget:
$2,000.00",Fixed price Intermediate,N/A,N/A,$2,Payment verified,"We're looking for a Senior Backend Engineer to join our fast-moving and highly collaborative engineering team. This is a hands-on, part-time, remote role where you’ll help build and scale the core infrastructure powering our AI agents—from data ingestion to real-time query handling. You’ll work closely with the founding team to architect, develop, and ship high-performance systems that integrate deeply into customer ecosystems like TMSs, FMSs, factoring portals, and ERPs. This is a unique opportunity to help define engineering best practices in a product-led AI company at an early stage. What You’ll Do Design and build scalable backend systems to support AI-driven customer support workflows Develop and maintain robust APIs, pipelines, and audit engines Integrate with customer systems (ERP, TMS, FMS, factoring portals) Collaborate with AI/ML teams to productionize and scale model outputs Implement observability, monitoring, and logging best practices Contribute to frontend updates when needed (light touch) Help shape engineering culture and standards in a fast-paced environment What We’re Looking For 2+ years experience building backend systems in production Strong proficiency in Python, Node.js, and Flask Solid understanding of REST APIs, microservices, and event-driven architectures Hands-on experience with PostgreSQL, MongoDB, or other SQL/NoSQL databases Experience working with cloud platforms (GCP preferred) and containerized environments (Docker/Kubernetes) Strong communication skills and ability to thrive in a remote-first, asynchronous team Proactive, ownership-driven mindset with the ability to move fast and iterate Nice to Have Exposure to AI/ML workflows and integrating ML model outputs into production systems Experience with message queues (e.g., SQS, Kafka) Background in building secure, enterprise-grade backend software Familiarity with frontend JavaScript frameworks",2025-08-07 20:39:01
Data Engineer,Experienced Cloud/Data Architect Needed for Government Projects,https://www.upwork.com/jobs/Experienced-Cloud-span-class-highlight-Data-span-Architect-Needed-for-Government-Projects_~021953475068220338973/?referrer_url_path=/nx/search/jobs/,"Python, SQL, Cloud Computing, Microsoft Excel, Architectural Design","$69
spent","Est. time:
1 to 3 months, 30+ hrs/week",Hourly Expert,N/A,N/A,N/A,Payment verified,"We are seeking a skilled Cloud/Data Architect with experience in a government work environment. The ideal candidate will have a strong understanding of cloud technologies, data architecture, and compliance requirements specific to government projects. You must be based in Australia and able to collaborate effectively with our team. Your expertise will help us design and implement robust cloud solutions that meet the unique needs of our government clients.",2025-08-07 20:16:03
Data Engineer,AI/Data Engineer with Langchain Experience Needed in Australia,https://www.upwork.com/jobs/span-class-highlight-Data-span-span-class-highlight-Engineer-span-with-Langchain-Experience-Needed-Australia_~021953474038857190766/?referrer_url_path=/nx/search/jobs/,"Data Analysis, Data Science, Python, Machine Learning, Artificial Intelligence","$69
spent","Est. time:
1 to 3 months, 30+ hrs/week",Hourly Intermediate,N/A,N/A,N/A,Payment verified,"**Job Description: AI/Data Engineer** We are excited to announce an opportunity for a talented AI/Data Engineer to join our dynamic team based in Australia. Our organization is at the forefront of innovation, leveraging cutting-edge technology to drive impactful solutions, and we are looking for a dedicated professional to help us further our mission. The ideal candidate will possess a rich blend of technical expertise, a passion for engineering, and experience working within a government environment. This role is critical to our success, as you will be instrumental in developing and maintaining complex pipelines that are essential for powering our AI initiatives. **Key Responsibilities:** As an AI/ , you will take on a variety of responsibilities that include, but are not limited to: 1. ** Pipeline Development:** Design, develop, and optimize robust pipelines that enable the seamless flow of from various sources to our analytical systems. You will ensure that these pipelines are efficient and scalable, meeting the demands of our growing needs. 2. **Langchain Utilization:** Utilize your familiarity with Langchain to build and manage workflows that integrate with our existing systems and enhance our AI capabilities. Your understanding of this technology will be pivotal in driving the success of our projects. 3. **Collaboration with Cross-Functional Teams:** Work closely with scientists, analysts, and other stakeholders to understand their requirements and translate them into effective solutions. Your ability to communicate effectively and collaborate across teams will ensure that our projects align with organizational goals. 4. ** Quality Assurance:** Implement quality checks and validation processes to ensure the accuracy and reliability of the being processed. You will play a vital role in maintaining the integrity of our systems. 5. **Continuous Improvement:** Stay up-to-date with the latest trends and technologies in engineering and AI. You will be expected to propose and implement improvements to our existing workflows, ensuring that we remain competitive in this rapidly evolving field. 6. **Documentation and Reporting:** Maintain comprehensive documentation of workflows, processes, and architectural designs. You will also be responsible for generating reports that provide insights into usage and performance metrics. **Qualifications:** To be successful in this role, candidates should possess the following qualifications: - A degree in Computer Science, Engineering, or a related field. - Proven experience as a or in a similar role, particularly within a government context. - Strong proficiency in pipeline technologies and frameworks, with a focus on best practices for management. - Familiarity with Langchain and its applications in workflows. - Excellent problem-solving skills and the ability to work independently as well as part of a team. - Strong communication skills, both verbal and written, to effectively convey technical concepts to non-technical stakeholders. **Why Join Us?** At our organization, we value innovation, collaboration, and a commitment to excellence. As part of our team, you will have the opportunity to work on exciting projects that leverage the power of AI and to make a meaningful impact. We offer a supportive work environment, opportunities for professional development, and a competitive salary package. If you are passionate about engineering, thrive in a collaborative and innovative environment, and meet the qualifications outlined above, we would love to hear from you. Please submit your application, including your resume and a cover letter detailing your relevant experience, and let us know why you would be a great fit for our team.",2025-08-07 20:12:06
Data Engineer,Senior Data Engineer,https://www.upwork.com/jobs/Senior-span-class-highlight-Data-span-span-class-highlight-Engineer-span_~021953412962093392361/?referrer_url_path=/nx/search/jobs/,"Data Engineering, Data Management, Data Science, Data Modeling","$1M+
spent","Est. time:
3 to 6 months, 30+ hrs/week",Hourly: Expert,$45.00,$75.00,N/A,Payment verified,"We are looking for a senior data engineer who can thrive in an environment where initiative and self-management is emphasized. You'd be working in a Python codebase, managing the data pipeline which loads from third party sources into versioned postgres databases, using dbt and custom Python code. Developers who also have some Building Science experience will be prioritized in the interview process (though, this is not a requirement). The client is in the climatetech space, and the success of the product depends upon being able to accurately describe and model buildiings. Requirements: * 10+ years of software engineering experience (demonstrated on your resume) with an emphasis on engineering * Experience building & running a pipeline at scale * Experience with DBT * Significant experience and expertise in Python * Significant experience and expertise with SQL * Understanding of OLAP oriented schema design * Demonstrable experience optimizing database schemas * Experience with postgres, with a good understanding of the internals and optimization Interview process: * Async video code interview - 1 hour * 1-2 rounds of technical interviews - 2-3 hours To have your application considered, please ensure you meet these criteria in your application: * You have attached a PDF resume (yes, Upwork _does_ allow this) which includes your education and details of experience since * You have written a no-BS zero-GPT cover note which briefly states why you are specifically relevant to this position (don't worry about writing too much here; we're primarily looking at experience level, though we do want to understand why you believe this to be a good fit) * You actually do have 10+ years of relevant experience If you're a good fit, this is a highly rewarding work environment, with significant autonomy, and opportunity to make a significant difference.",2025-08-07 16:52:09
Data Engineer,Senior Data Engineer – Snowflake | ADF | Python | APIs | Snowflake | Airflow | U.S. time zone,https://www.upwork.com/jobs/Senior-span-class-highlight-Data-span-span-class-highlight-Engineer-span-Snowflake-ADF-Python-APIs-Snowflake-Airflow-time-zone_~021953330444646413085/?referrer_url_path=/nx/search/jobs/,"Data Transformation, Data Engineering, Data Warehousing & ETL Software, Snowflake","$1K+
spent","Est. time:
More than 6 months, 30+ hrs/week",Hourly: Expert,$10.00,$15.00,N/A,Payment verified,"We are seeking a highly skilled Data Engineer to help build and scale our data pipelines within Snowflake. The initial phase will focus on ingesting data from Salesforce, with future expansion to other systems. You’ll be working with modern ELT tools and orchestrators, and will play a critical role in integrating AI agent workflows through Python-based API development. Responsibilities: • Ingest into Snowflake from multiple sources, starting with Salesforce. • Design and manage ELT pipelines using tools such as Airbyte, Airflow, or Azure Factory (ADF) (ADF preferred). • Write advanced SQL for modeling and transformation within Snowflake. • Develop and maintain Python APIs, especially for AI agent integration. • Ensure high performance, reliability, and quality across the stack. • Collaborate with cross-functional teams to deliver -driven solutions. Requirements: • 8+ years of experience in engineering or related roles. • Strong expertise with Snowflake (required). • Advanced skills in SQL (preferred) and Python (required). • Experience with API development and external service integration. • Hands-on experience with Airbyte, Airflow, or ADF (ADF highly preferred). • Bachelor’s degree in Computer Science or a related field. • Must be available to work during U.S. time zones (full 8 hours in EST or PST).",2025-08-07 10:52:11
Data Engineer,ETL Specialist Needed for Transforming Supplier CSV Data,https://www.upwork.com/jobs/ETL-Specialist-Needed-for-Transforming-Supplier-CSV-span-class-highlight-Data-span_~021953444504694934894/?referrer_url_path=/nx/search/jobs/,"Data Entry, Python, ETL Pipeline","$10K+
spent","Est. time:
1 to 3 months, Less than 30 hrs/week",Hourly: Intermediate,$8.00,$25.00,N/A,Payment verified,"We are looking for an experienced ETL specialist to help us automate and standardize the transformation of product data from our suppliers. We receive product data from four different suppliers, each with their own formatting, twice a year. Currently, importing this into our webshop is a time-consuming and error-prone process due to inconsistencies in structure and content. Your task: Develop an ETL solution that can automatically transform and standardize this supplier into our universal master format, ready for import into our webshop. Ideally, the output will be used in Airtable or a similar platform, functioning as a lightweight PIM (Product Information Management) system. Requirements: - Proven experience with ETL tools or custom-built pipelines - Strong skills in processing and transforming structured (especially CSV) - Ability to design reusable and scalable workflows for recurring imports - Familiarity with platforms like Airtable, SeaTable, Baserow, or similar tools - Basic understanding of e-commerce product (e.g. SKUs, sizes, variants, etc.) - Attention to detail and a focus on quality Bonus points for: - Experience with AI-assisted mapping (e.g. recognizing dominant color, material types) - Integration knowledge with Shopify or Magento - Experience building mini PIMs or internal management systems What we provide: - Examples of supplier files - Documentation of our preferred structure and field definitions - Support during implementation and testing If you’re passionate about building efficient, no-nonsense workflows and enjoy cleaning up messy , we’d love to hear from you!",2025-08-07 18:52:13
Data Engineer,End-to-End Data Platform Architect Needed,https://www.upwork.com/jobs/End-End-span-class-highlight-Data-span-Platform-Architect-Needed_~021953327449143707319/?referrer_url_path=/nx/search/jobs/,"JavaScript, Python, Web Development, HTML, CSS","$50K+
spent","Est. time:
1 to 3 months, Less than 30 hrs/week",Hourly: Expert,$50.00,$75.00,N/A,Payment verified,"We are seeking an experienced architect to design and implement an end-to-end data platform utilizing an open-source framework with enterprise capabilities. The ideal candidate will have a strong background in data architecture and experience with various technologies. You will work closely with our team to ensure that the platform meets our business needs, scalability, and security requirements. If you have a proven track record of building robust solutions, we would love to hear from you!",2025-08-07 10:52:16
Data Engineer,"Freelance Data Engineer – GCP Pipelines, Data Integration & AI Tagging",https://www.upwork.com/jobs/Freelance-span-class-highlight-Data-span-span-class-highlight-Engineer-span-GCP-Pipelines-span-class-highlight-Data-span-Integration-amp-Tagging_~021953412454509376285/?referrer_url_path=/nx/search/jobs/,"ETL Pipeline, Vertex AI, API Integration, LLM Prompt Engineering, Google Cloud Platform","$100+
spent","Est. time:
1 to 3 months, 30+ hrs/week",Hourly: Intermediate,$18.00,$38.00,N/A,Payment verified,"We’re building a tool for impact investors and need a freelance data engineer to: - Integrate Bright Data + user DB into BigQuery - Build Vertex AI Pipelines to orchestrate ingestion, cleaning, and classification - Improve data quality (deduplication, validation, harmonization) - Create a prompt-based GPT tagging tool for non-tech users - Ensure full GDPR compliance across workflows - Deliver clear pipeline docs & update playbook",2025-08-07 16:52:18
Data Engineer,Experienced Data Visualization Engineer (UI/UX) – Remote – Long-Term Automotive Project,https://www.upwork.com/jobs/Experienced-span-class-highlight-Data-span-Visualization-span-class-highlight-Engineer-span-Remote-Long-Term-Automotive-Project_~021953422489412985321/?referrer_url_path=/nx/search/jobs/,Data Visualization,"$0
spent","Est. time:
More than 6 months, 30+ hrs/week",Hourly Intermediate,N/A,N/A,N/A,Payment verified,"We are currently looking for a Data Visualization Engineer (w/m/d) to support a long-term remote project in the automotive industry. This is a 3-year engagement starting in October 2025. As a Data Visualization Engineer, you will design intuitive user interfaces, interaction flows, and dashboard structures for complex applications. You should bring strong experience in UI/UX design principles and visualization best practices. Responsibilities: - Design UI/UX for interactive platforms - Create interaction concepts for intuitive and efficient user experiences - Develop sitemaps, wireframes, flowcharts - Build low- and high-fidelity prototypes for design proposals - Collaborate with cross-functional teams including Engineers and Product Owners Start Date: 01/10/2025 Duration: Until 30/09/2028 Location: 100% Remote Industry: Automotive Seniority: Advanced Working Language: German or English Time Zone Compatibility: CET",2025-08-07 19:52:21
Data Engineer,Data Pipeline Modification Expert Needed,https://www.upwork.com/jobs/span-class-highlight-Data-span-Pipeline-Modification-Expert-Needed_~021953338352018851511/?referrer_url_path=/nx/search/jobs/,"Data Scraping, Data Mining, Python, ETL Pipeline, Microsoft Excel","$93
spent","Est. time:
1 to 3 months, Less than 30 hrs/week",Hourly: Intermediate,$8.00,$25.00,N/A,Payment verified,"We are seeking an experienced professional to make necessary changes to our existing data pipeline. The ideal candidate should have a strong background in data engineering and be able to identify areas of improvement to enhance efficiency and reliability. You'll be responsible for analyzing current workflows, implementing changes, and ensuring seamless flow. Excellent problem-solving skills and attention to detail are crucial for this role.",2025-08-07 11:52:23
