Search Query,Title,Job Link,Tags,Client Spent,Payment Info,Budget Type,Lower Hourly Rate,Higher Hourly Rate,Fixed Price,Payment Verified/Unverified,Description,Posted Time
ETL,Experienced Data Engineer Needed for Data Pipeline Development,https://www.upwork.com/jobs/Experienced-Data-Engineer-Needed-for-Data-Pipeline-Development_~021953753237341110540/?referrer_url_path=/nx/search/jobs/,"ETL Pipeline, Python, Big Data, Microsoft Excel, Data Science","$60K+
spent","Est. time:
1 to 3 months, 30+ hrs/week",Hourly: Expert,$20.00,$75.00,N/A,Payment verified,"We’re building a high-velocity data platform that powers marketing integrations between our application and third-party platforms (e.g., ad networks, CRMs, analytics tools). We’re looking for a Senior Data Engineer with strong experience in Google Cloud and API-based data workflows. You’ll be responsible for owning and scaling our data pipelines both for importing data from external platforms and exporting updates back to them. (r) We’re 80% of the way there with our current architecture but we’re looking for someone who can move fast, bring strong opinions, and work with AI tools to accelerate delivery. --- ### What You’ll Be Working On: 🔁 Data Import Pipelines - Extract data from various external APIs (e.g., Meta Ads, Google Ads, Tiktok Ads, Stripe, PayPal, Shopify) - Model and transform data with interdependent tables - Trigger integrations **manually** or on a **schedule** - Trigger downstream jobs on completion (e.g., import completion → trigger transformation/export) 📤 Data Export Pipelines - Automatically push processed data back to third-party platforms via their APIs - Ensure data syncing and deduplication logic is solid and scalable --- Our Tech Stack is on Google Cloud Platform (GCP): BigQuery, Cloud Functions, Pub/Sub, Cloud Scheduler, Cloud Run, Airflow, Firebase --- What We’re Looking For: - 5+ years of data engineering experience (preferably with GCP) - Strong background in **API integrations** and building robust /ELT pipelines - Hands-on experience with **event-driven architectures** and **dependency-aware workflows** - Ability to **work autonomously** and **move fast** - Comfortable using **AI tools to accelerate development** (e.g., coding assistants, prompt engineering) - You write clean, modular, and testable code --- Why Join Us? - **Shape the foundation** – As one of our first engineers, you’ll have outsized impact on our product, tech stack, and culture. - **Build with real users in mind** – We’re not guessing. We’ve got paying customers, real data, and real problems to solve. - **Work directly with founders** – Move fast, make decisions, and build without red tape or layers of management. - **Own meaningful systems** – From data ingestion to ML-driven insights, you’ll architect systems that power a next-gen analytics platform. --- To Apply: We won't consider generic applications. To be considered please include the following in your application 1. What data and cloud tools have you used most recently? 2. Describe a complex integration or pipeline you’ve built. 3. Have you used AI (e.g., GitHub Copilot, ChatGPT) to assist in development? If so, how?",2025-08-08 14:41:54
ETL,Microsoft Fabric Data Engineer,https://www.upwork.com/jobs/Microsoft-Fabric-Data-Engineer_~021953651182953857292/?referrer_url_path=/nx/search/jobs/,"ETL Pipeline, PySpark, Data Modeling, Data Ingestion, SQL, Python, Power Query","$5K+
spent","Est. time:
3 to 6 months, Less than 30 hrs/week",Hourly Expert,N/A,N/A,N/A,Payment verified,"Microsoft Fabric Data Engineer Role Summary The Microsoft Fabric Data Engineer will be responsible for designing, developing, and maintaining scalable data pipelines and architectures within the Microsoft Fabric ecosystem to enable advanced analytics, reporting solutions. This includes working with OneLake, Lakehouses, Dataflows, Pipelines, and Notebooks within a unified, SaaS-based data platform. Core Responsibilities oDesign and implement data ingestion pipelines using Data Pipelines in Microsoft Fabric. oBuild and manage Lakehouses and Warehouses leveraging OneLake as the unified storage layer. oDevelop Spark-based notebooks for data transformation, cleansing, and advanced analytics. oCreate and orchestrate Dataflows Gen2 for repeatable processes. oCollaborate with Power BI developers and business analysts. oOptimize performance and scalability of Fabric workloads. oImplement security and access controls on datasets across domains. Key Skills and Expertise Data Engineering o/ELT pipeline development oData modeling (Star, Snowflake) oWorking with structured, semi-structured, and unstructured data Microsoft Fabric Components oOneLake (central data lake) oLakehouses oData Pipelines (based on ADF concepts) oDataflows Gen2 oNotebooks (PySpark) oWarehouses (SQL analytics engine) Tools & Languages oSQL (T-SQL, Spark SQL) oPython / PySpark oDAX / M (Power Query) oPower BI Soft Skills oStrong communication and stakeholder engagement oAgile & collaborative mindset oProblem-solving and analytical thinking oDocumentation and knowledge sharing Recommended Experience o3–6 years in Data Engineering or BI roles oHands-on with Microsoft Azure Data Services (prior to Fabric): Azure Data Factory, Synapse, ADLS, Databricks oFamiliarity with Power BI for end-to-end workflows oExposure to data mesh or domain-oriented architectures is a plus",2025-08-08 08:34:56
ETL,Experienced ETL Engineer Needed for Data Pipeline Development,https://www.upwork.com/jobs/Experienced-span-class-highlight-ETL-span-Engineer-Needed-for-Data-Pipeline-Development_~021953732924398188618/?referrer_url_path=/nx/search/jobs/,"ETL Pipeline, ETL, Python, Apache Spark, Big Data","$0
spent","Est. budget:
$120.00",Fixed price Intermediate,N/A,N/A,$120.00,Payment unverified,"We are seeking an experienced ETL Engineer to design and implement robust data pipelines. You will be responsible for extracting data from various sources, transforming it into a suitable format, and loading it into our data warehouse. The ideal candidate will have a solid understanding of processes and tools, along with the ability to work collaboratively with our data analytics team. If you are passionate about data and have a proven track record in development, we would love to hear from you!",2025-08-08 13:34:58
ETL,Looking for Full-Stack Developer – Horse Racing Database,https://www.upwork.com/jobs/Looking-for-Full-Stack-Developer-Horse-Racing-Database_~021953605247934693644/?referrer_url_path=/nx/search/jobs/,"ETL, Database Development, Database Design, Data Integration","$500
spent","Est. time:
1 to 3 months, Less than 30 hrs/week",Hourly Expert,N/A,N/A,N/A,Payment verified,"Looking for an experienced full stack developer to design and build from scratch a horse racing database and a front end interface. The project will consolidate data from multiple sources (mainly CSV files) into a high performance, relational database, with a private racing form analysis page that combines information from all tables for in depth study and decision-making (not public facing). I’m looking for your recommendations on the optimal table structures and relationships to support analysis, back testing, and potential future machine learning. Please include in your proposal: Relevant database experience (especially with racing or sports data) Examples of similar projects Fixed price estimate and timeline for an initial working version",2025-08-08 05:35:00
ETL,Automate Data Extraction from .DWG to Excel,https://www.upwork.com/jobs/Automate-Data-Extraction-from-DWG-Excel_~021953739014527596618/?referrer_url_path=/nx/search/jobs/,"Microsoft Excel, Data Scraping, Visual Basic for Applications, Data Extraction","$2K+
spent","Est. budget:
$50.00",Fixed price Intermediate,N/A,N/A,$50.00,Payment verified,"**Job Description:** Need to automate data extraction from .dwg files to Excel. The ideal candidate will have expertise in excel automation and data manipulation. More details on chat. All proposals will be viewed and contacted, so your connects are not wasted.",2025-08-08 14:35:03
ETL,Data Extraction and Web Setup for Real Estate Purchase Agreements,https://www.upwork.com/jobs/Data-Extraction-and-Web-Setup-for-Real-Estate-Purchase-Agreements_~021953745997503684361/?referrer_url_path=/nx/search/jobs/,"JavaScript, Data Entry, Data Scraping, HTML, CSS, SQL Programming","$10
spent","Est. time:
1 to 3 months, Less than 30 hrs/week",Hourly: Intermediate,$8.00,$100.00,N/A,Payment verified,"We are seeking a detail-oriented freelancer to help extract data from a CSV file containing purchase agreements for real estate properties, including apartments and houses. The extracted data needs to be formatted and set up on our webpage like this one: https://fastinn.is/kaupsamningar. The ideal candidate will have experience with CSV data manipulation and web integration. Attention to detail and accuracy is crucial to ensure all information is correctly captured and displayed.",2025-08-08 14:35:05
ETL,Huge team for Data scraping and task,https://www.upwork.com/jobs/Huge-team-for-Data-scraping-and-task_~021953605084071671882/?referrer_url_path=/nx/search/jobs/,"Python, Data Scraping, Data Mining, Data Entry, Data Extraction, Microsoft Excel","$1K+
spent","Est. budget:
$500.00",Fixed price Entry Level,N/A,N/A,$500.00,Payment verified,Looking for someone who has a huge team that can handle thousands of records per day with data scraping and other research on websites. I have many task,2025-08-08 05:35:07
ETL,ETL Specialist Needed for Transforming Supplier CSV Data,https://www.upwork.com/jobs/span-class-highlight-ETL-span-Specialist-Needed-for-Transforming-Supplier-CSV-Data_~021953444504694934894/?referrer_url_path=/nx/search/jobs/,"ETL Pipeline, Data Entry, Python","$10K+
spent","Est. time:
1 to 3 months, Less than 30 hrs/week",Hourly: Intermediate,$8.00,$25.00,N/A,Payment verified,"We are looking for an experienced ETL specialist to help us automate and standardize the transformation of product data from our suppliers. We receive product data from four different suppliers, each with their own formatting, twice a year. Currently, importing this data into our webshop is a time-consuming and error-prone process due to inconsistencies in structure and content. Your task: Develop an solution that can automatically transform and standardize this supplier data into our universal master data format, ready for import into our webshop. Ideally, the output will be used in Airtable or a similar platform, functioning as a lightweight PIM (Product Information Management) system. Requirements: - Proven experience with tools or custom-built data pipelines - Strong skills in processing and transforming structured data (especially CSV) - Ability to design reusable and scalable workflows for recurring imports - Familiarity with platforms like Airtable, SeaTable, Baserow, or similar tools - Basic understanding of e-commerce product data (e.g. SKUs, sizes, variants, etc.) - Attention to detail and a focus on data quality Bonus points for: - Experience with AI-assisted mapping (e.g. recognizing dominant color, material types) - Integration knowledge with Shopify or Magento - Experience building mini PIMs or internal data management systems What we provide: - Examples of supplier files - Documentation of our preferred structure and field definitions - Support during implementation and testing If you’re passionate about building efficient, no-nonsense data workflows and enjoy cleaning up messy data, we’d love to hear from you!",2025-08-08 15:35:09
ETL,Data Engineer – Web Crawling & ETL Pipelines for Market Listings,https://www.upwork.com/jobs/Data-Engineer-Web-Crawling-amp-span-class-highlight-ETL-span-Pipelines-for-Market-Listings_~021953582782961451276/?referrer_url_path=/nx/search/jobs/,"ETL Pipeline, Data Scraping, Data Science","$1K+
spent","Est. time:
More than 6 months, 30+ hrs/week",Hourly Expert,N/A,N/A,N/A,Payment verified,"oin us to design crawlers and pipelines to ingest real estate listing data. You'll also support grounding data used by LLMs for analysis. Responsibilities: Develop scalable scrapers and API integrations Build ETL pipelines to normalize listing data Integrate external market data via APIs Tech Stack: Python, AWS Glue/Lambda, Step Functions, Perplexity API Skills: Web scraping best practices (ethics, reliability) and data pipeline development Bonus: Experience with real estate data or comparables",2025-08-08 03:35:12
ETL,Senior Data Engineer,https://www.upwork.com/jobs/Senior-Data-Engineer_~021953412962093392361/?referrer_url_path=/nx/search/jobs/,"Database Architecture, Data Engineering, dbt, Python, SQL, Data Management","$1M+
spent","Est. time:
3 to 6 months, 30+ hrs/week",Hourly: Expert,$45.00,$75.00,N/A,Payment verified,"We are looking for a senior data engineer who can thrive in an environment where initiative and self-management is emphasized. You'd be working in a Python codebase, managing the data pipeline which loads from third party sources into versioned postgres databases, using dbt and custom Python code. Developers who also have some Building Science experience will be prioritized in the interview process (though, this is not a requirement). The client is in the climatetech space, and the success of the product depends upon being able to accurately describe and model buildiings. Requirements: * 10+ years of software engineering experience (demonstrated on your resume) with an emphasis on data engineering * Experience building & running a data pipeline at scale * Experience with DBT * Significant experience and expertise in Python * Significant experience and expertise with SQL * Understanding of OLAP oriented schema design * Demonstrable experience optimizing database schemas * Experience with postgres, with a good understanding of the internals and optimization Interview process: * Async video code interview - 1 hour * 1-2 rounds of technical interviews - 2-3 hours To have your application considered, please ensure you meet these criteria in your application: * You have attached a PDF resume (yes, Upwork _does_ allow this) which includes your education and details of experience since * You have written a no-BS zero-GPT cover note which briefly states why you are specifically relevant to this position (don't worry about writing too much here; we're primarily looking at experience level, though we do want to understand why you believe this to be a good fit) * You actually do have 10+ years of relevant experience If you're a good fit, this is a highly rewarding work environment, with significant autonomy, and opportunity to make a significant difference.",2025-08-08 15:35:14
